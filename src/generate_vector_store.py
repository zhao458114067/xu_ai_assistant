import os
import nltk
from tqdm import tqdm
from langchain.document_loaders import UnstructuredFileLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings

DATA_PATH = "D:\idea_workspace\zx-rich\src"
VECTOR_STORE_PATH = "../vector_store"

def load_documents(path: str):
    documents = []
    file_list = []

    for root, dirs, files in os.walk(path):
        dirs[:] = [d for d in dirs if not d.startswith('.') and d != "__pycache__"]
        for file in files:
            if file.startswith('.'):
                continue
            file_list.append(os.path.join(root, file))

    print(f"ğŸ“„ å…±å‘ç° {len(file_list)} ä¸ªæ–‡ä»¶ï¼Œå¼€å§‹åŠ è½½â€¦")

    for filepath in tqdm(file_list, desc="åŠ è½½æ–‡æ¡£"):
        try:
            loader = UnstructuredFileLoader(filepath)
            documents.extend(loader.load())
        except Exception as e:
            print(f"âš ï¸ è·³è¿‡ {filepath}ï¼ˆåŸå› ï¼š{e}ï¼‰")
    return documents

def main():
    print("æ­£åœ¨åŠ è½½æ–‡æ¡£...")
    documents = load_documents(DATA_PATH)

    print("æ­£åœ¨åˆ‡åˆ†æ–‡æœ¬...")
    splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=100)
    chunks = splitter.split_documents(documents)
    print(f"å…±åˆ‡åˆ†ä¸º {len(chunks)} ä¸ªæ–‡æœ¬å—")

    print("æ­£åœ¨åˆ›å»ºå‘é‡åº“ï¼ˆä½¿ç”¨ bge-small-zhï¼‰...")
    embeddings = HuggingFaceEmbeddings(
        model_name="BAAI/bge-small-zh",
        model_kwargs={"device": "cpu"}
    )

    # åŠ ä¸ŠåµŒå…¥è¿›åº¦æ¡
    vectors = []
    for chunk in tqdm(chunks, desc="ç”ŸæˆåµŒå…¥"):
        vectors.append(chunk)
    vectorstore = FAISS.from_documents(vectors, embeddings)

    print("æ­£åœ¨ä¿å­˜å‘é‡æ•°æ®åº“...")
    vectorstore.save_local(VECTOR_STORE_PATH)
    print("å®Œæˆï¼ä½ ç°åœ¨å¯ä»¥å¼€å§‹æé—®äº†")

if __name__ == "__main__":
    nltk.download('punkt')
    main()
